{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imported Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import os\n",
    "from scipy.stats import zscore\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from IPython.display import display as original_display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import inspect\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean labels in any plot functions\n",
    "def clean_label(label):\n",
    "    try:\n",
    "        return label.replace('_', ' ').title()\n",
    "    except AttributeError as e:\n",
    "        print(f'Error cleaning label: {e}')\n",
    "        return label\n",
    " \n",
    "# Function for getting the name of a DataFrame\n",
    "def get_var_name(var):\n",
    "    try:\n",
    "        for name, value in globals().items():\n",
    "            if value is var:\n",
    "                return name\n",
    "    except Exception as e:\n",
    "        print(f'Error getting variable name: {e}')\n",
    "    return None\n",
    "\n",
    "# Function to validate the data in a DataFrame\n",
    "def validate_data(df, show_counts=True):\n",
    "    try:\n",
    "        df_name = get_var_name(df)\n",
    "        print(f'#########################################################################################################################################################################################\\nDataFrame: {df_name}')\n",
    "        # Snapshot the dataset\n",
    "        display(df)\n",
    "        # Check for unique values\n",
    "        unique_counts = pd.DataFrame(df.nunique())\n",
    "        unique_counts = unique_counts.reset_index().rename(columns={0:'No. of Unique Values', 'index':'Field Name'})\n",
    "        print(\"Unique values per field:\")\n",
    "        pd.set_option('display.max_rows', None)\n",
    "        display(unique_counts)\n",
    "        pd.reset_option('display.max_rows')\n",
    "        # Checking for duplicates\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        print(\"\\nNumber of duplicate rows:\")\n",
    "        print(duplicate_count,'\\n')\n",
    "        info = df.info(show_counts=show_counts)\n",
    "        display(info)\n",
    "        # Summary stats\n",
    "        print(\"\\nSummary statistics:\")\n",
    "        display(df.describe())\n",
    "        print('End of data validation\\n#########################################################################################################################################################################################\\n')\n",
    "    except Exception as e:\n",
    "        print(f'Error validating data: {e}')\n",
    " \n",
    "# Function to provide list for data sources as a DataFrame when conducting analysis\n",
    "def header_list(df):\n",
    "    try:\n",
    "        df_list_ = df.copy()\n",
    "        df_list = df_list_.columns.tolist()\n",
    "        df_list = pd.DataFrame(df_list)\n",
    "        new_header = df_list.iloc[0]  # Get the first row for the header\n",
    "        df_list = df_list[1:]  # Take the data less the header row\n",
    "        df_list.columns = new_header  # Set the header row as the df header\n",
    "        df_list.reset_index(drop=True, inplace=True)  # Reset index\n",
    "        return df_list\n",
    "    except Exception as e:\n",
    "        print(f'Error creating header list: {e}')\n",
    "        return pd.DataFrame()\n",
    " \n",
    "def query_data(schema, data):\n",
    "    try:\n",
    "        # Define the SQL query\n",
    "        query = f'SELECT * FROM [{schema}].[{data}]'\n",
    "        # Load data into DataFrame\n",
    "        df = pd.read_sql(query, engine)\n",
    "        print(f'Successfully imported {data}')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error querying data: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def display(df):\n",
    "    try:\n",
    "        frame = inspect.currentframe().f_back\n",
    "        name = \"Unnamed DataFrame\"\n",
    "        for var_name, var_value in frame.f_locals.items():\n",
    "            if var_value is df:\n",
    "                name = var_name\n",
    "                break\n",
    "        if name not in {'df', 'Unnamed DataFrame', 'unique_counts'}:\n",
    "            print(f\"DataFrame: {name}\")\n",
    "        original_display(df)\n",
    "    except Exception as e:\n",
    "        print(f'Error displaying DataFrame: {e}')\n",
    "\n",
    "def unique_values(df, display_df=True):\n",
    "    try:\n",
    "        unique_values = {col: df[col].unique() for col in df.columns}\n",
    "        max_length = max(len(values) for values in unique_values.values())\n",
    "        unique_df_data = {}\n",
    "        for col, values in unique_values.items():\n",
    "            unique_df_data[col] = list(values) + [None] * (max_length - len(values))\n",
    "        unique_df = pd.DataFrame(unique_df_data)\n",
    "        if display_df:\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            display(unique_df.head(100))\n",
    "            pd.reset_option('display.max_rows')\n",
    "        return unique_df\n",
    "    except Exception as e:\n",
    "        print(f'Error extracting unique values: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def export_to_csv(df, **kwargs):\n",
    "    try:\n",
    "        # Obtaining wanted directory\n",
    "        directory = kwargs.get('directory',r\"C:\\Users\\jf79\\OneDrive - Office Shared Service\\Documents\\H&F Analysis\\Python CSV Repositry\")\n",
    "        \n",
    "        # Obtaining name of DataFrame\n",
    "        df_name = kwargs.get('df_name',get_var_name(df))\n",
    "        if not isinstance(df_name, str) or df_name == '_':\n",
    "                df_name = input('Dataframe not found in global variables. Please enter a name for the DataFrame: ')\n",
    "\n",
    "        file_path = f'{directory}\\\\{df_name}.csv'\n",
    "\n",
    "        print(f'Exproting {df_name} to CSV...\\n@ {file_path}\\n')\n",
    "        df.to_csv(file_path, index=False)\n",
    "        print(f'Successfully exported {df_name} to CSV')\n",
    "    except Exception as e:\n",
    "        print(f'Error exporting to CSV: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_features(df, date='count_date', **kwargs):\n",
    "    print('Applying features...')\n",
    "    try:\n",
    "        df[date] = pd.to_datetime(df[date])\n",
    "        df['year'] = df[date].dt.year\n",
    "        df['day_name'] = df[date].dt.dayofweek\n",
    "\n",
    "        day_dict = {\n",
    "            '0':['Monday','Weekday'],\n",
    "            '1':['Tuesday','Weekday'],\n",
    "            '2':['Wednesday','Weekday'],\n",
    "            '3':['Thursday','Weekday'],\n",
    "            '4':['Friday','Weekday'],\n",
    "            '5':['Saturday','Weekend'],\n",
    "            '6':['Sunday','Weekend']\n",
    "        }\n",
    "\n",
    "        df['day_name'] = df['day_name'].astype(str)\n",
    "        df['week_name'] = df['day_name'].map(lambda x: day_dict[x][1])\n",
    "        df['day_name'] = df['day_name'].map(lambda x: day_dict[x][0])\n",
    "        \n",
    "        time = kwargs.get('time', False)\n",
    "        if time:\n",
    "            try:\n",
    "                time_dict = {\n",
    "                    '00-03':'6pm-6am',\n",
    "                    '03-06':'6pm-6am',\n",
    "                    '06-09':'6am-6pm',\n",
    "                    '09-12':'6am-6pm',\n",
    "                    '12-15':'6am-6pm',\n",
    "                    '15-18':'6am-6pm',\n",
    "                    '18-21':'6pm-6am',\n",
    "                    '21-24':'6pm-6am'\n",
    "                }\n",
    "                df['day_night'] = df[time].map(time_dict)\n",
    "            except KeyError as e:\n",
    "                print(f'Invalid time column: {e}')\n",
    "        \n",
    "        print('Features applied.')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error applying features: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def detect_anomalies(df, **kwargs):\n",
    "    print('Detecting anomalies...')\n",
    "    try:\n",
    "        used_keys = {\n",
    "            'footfall_type','day_night',\n",
    "            'agg','std','primary_key'\n",
    "        }\n",
    "        redundant_kwargs = set(kwargs.keys()) - used_keys\n",
    "        if redundant_kwargs:\n",
    "            print(f'Redundant kwargs: {redundant_kwargs}')\n",
    "            return pd.DataFrame()\n",
    "        kwargs = {key: kwargs.get(key, f'default_value_{key}') for key in used_keys}\n",
    "        \n",
    "        footfall_type = kwargs.get('footfall_type')\n",
    "        agg = kwargs.get('agg')\n",
    "        categories = [\n",
    "            'count_date',f'{footfall_type}_{agg}',\n",
    "            'zscore','year','is_anomaly?',\n",
    "            'day_name','week_name','day_night'\n",
    "        ]\n",
    "        keywords = [\n",
    "            kwargs.get('primary_key'),\n",
    "        ]\n",
    "        for keyword in keywords:\n",
    "            if keyword:\n",
    "                if type(keyword) is not list:\n",
    "                    keyword = [keyword]\n",
    "                for word in keyword:\n",
    "                    categories = categories + [f'{word}']\n",
    "\n",
    "        std = kwargs.get('std', 3)\n",
    "        anomalies = df.copy()\n",
    "        anomalies['zscore'] = anomalies.groupby(keywords)[f'{footfall_type}_{agg}'].transform(zscore)\n",
    "        anomalies['is_anomaly?'] = (anomalies['zscore'] < -std) | (anomalies['zscore'] > std)\n",
    "        num_anomalies = anomalies['is_anomaly'].sum()\n",
    "        print(f'{num_anomalies} anomalies have been detected.')\n",
    "\n",
    "        anomalies = anomalies[categories]\n",
    "        anomalies['moving_average'] = anomalies.groupby(keywords)[f'{footfall_type}_{agg}'].transform(lambda x: x.rolling(window=7).mean())\n",
    "        anomalies['corrected_value'] = np.where(\n",
    "            anomalies['is_anomaly?'],\n",
    "            anomalies['moving_average'],anomalies[f'{footfall_type}_{agg}']\n",
    "        )\n",
    "        anomalies['corrected_ma_monthly'] = anomalies.groupby(keywords)['corrected_value'].transform(lambda x: x.rolling(window=30).mean())\n",
    "        anomalies['corrected_ma_weekly'] = anomalies.groupby(keywords)['corrected_value'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "        print('Anomalies have been flagged and corrected.')\n",
    "        return anomalies\n",
    "    except Exception as e:\n",
    "        print(f'Error detecting anomalies: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def agg_footfall_data(df, **kwargs):\n",
    "    print('Aggregating footfall data...')\n",
    "    try:\n",
    "        used_keys = {\n",
    "            'category','day_night',\n",
    "            'agg', 'footfall_type'\n",
    "        }\n",
    "        redundant_kwargs = set(kwargs.keys()) - used_keys\n",
    "        if redundant_kwargs:\n",
    "            print(f'Redundant kwargs: {redundant_kwargs}')\n",
    "            return pd.DataFrame()\n",
    "        unused_keys = set(used_keys) - set(kwargs.keys())\n",
    "        if unused_keys:\n",
    "            print(f'Missing kwargs: {unused_keys}\\nThese args will be set to default values')\n",
    "        \n",
    "        df = apply_features(df, time='time_indicator')\n",
    "\n",
    "        merge_list = ['day_name','week_name','day_night','count_date']\n",
    "        new_categories = [\n",
    "            'count_date','day_name','week_name','day_night',\n",
    "            'corrected_ma_monthly','corrected_ma_weekly',\n",
    "            'corrected_value',\n",
    "        ]\n",
    "        category = kwargs.get('category')\n",
    "        keywords = [\n",
    "            kwargs.get('category')\n",
    "        ]\n",
    "        for keyword in keywords:\n",
    "            if keyword:\n",
    "                if not isinstance(keyword, list):\n",
    "                    keyword = [keyword]\n",
    "                for word in keyword:\n",
    "                    merge_list = [f'{word}'] + merge_list\n",
    "                    new_categories = new_categories + [f'{word}']\n",
    "        \n",
    "        agg = kwargs.get('agg','sum')\n",
    "        agg_data = df.groupby(merge_list + ['year']).agg(\n",
    "            residents_sum = ('resident',f'{agg}'),\n",
    "            workers_sum = ('worker',f'{agg}'),\n",
    "            visitors_sum = ('visitor',f'{agg}'),\n",
    "            loyalty = ('loyalty_percentage','mean'),\n",
    "            dwell_time = ('dwell_time',f'{agg}')\n",
    "        )\n",
    "        agg_data = agg_data.reset_index()\n",
    "        agg_data = agg_data.sort_values(\n",
    "            ['count_date'],\n",
    "            ascending=False\n",
    "        )\n",
    "\n",
    "        default_values = ['residents','workers','visitors']\n",
    "        footfall_type = kwargs.get('footfall_type', default_values)\n",
    "        anomalies = {}\n",
    "        i = 0\n",
    "        for footfall in footfall_type:\n",
    "            if footfall not in default_values:\n",
    "                raise KeyError(f'Invalid footfall type: [{footfall}]')\n",
    "        for footfall in footfall_type:\n",
    "            i = i + 1\n",
    "            anomalies[f'{footfall}_z'] = detect_anomalies(agg_data,footfall_type=footfall,std=2.6,primary_key=category,agg=agg)\n",
    "            if i > len(footfall_type)-1:\n",
    "                new_categories = new_categories + ['year']\n",
    "            anomalies[f'{footfall}_z'] = anomalies[f'{footfall}_z'][new_categories]\n",
    "\n",
    "        footfall_data = pd.merge(\n",
    "            anomalies['residents_z'], anomalies['workers_z'],\n",
    "            how='left', on=merge_list,\n",
    "            suffixes=['_residents','_workers']\n",
    "        ).merge(\n",
    "            anomalies['visitors_z'],\n",
    "            how='left', on=merge_list,\n",
    "        ).rename(columns={\n",
    "                'corrected_value':'corrected_value_visitors',\n",
    "                'corrected_ma_monthly':'corrected_ma_monthly_visitors',\n",
    "                'corrected_ma_weekly':'corrected_ma_weekly_visitors'\n",
    "            }\n",
    "        )\n",
    "        for footfall in footfall_type:\n",
    "            if footfall not in default_values:\n",
    "                raise KeyError(f'Invalid footfall type: [{footfall}]')\n",
    "        for footfall in footfall_type:\n",
    "            footfall_data['corrected_value_total'] = 0\n",
    "            footfall_data['corrected_value_total'] = footfall_data['corrected_value_total'] + footfall_data[f'corrected_value_{footfall}']\n",
    "        footfall_data['corrected_value_total'].fillna(0, inplace=True)\n",
    "        footfall_data['corrected_ma_monthly_total'] = footfall_data.groupby(keywords)['corrected_value_total'].transform(lambda x: x.rolling(window=30).mean())\n",
    "        footfall_data['corrected_ma_weekly_total'] = footfall_data.groupby(keywords)['corrected_value_total'].transform(lambda x: x.rolling(window=7).mean())\n",
    "\n",
    "        print('Footfall Data Aggregated.')\n",
    "        return footfall_data\n",
    "    except Exception as e:\n",
    "        print(f'Error aggregating footfall data: {e}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def transform_to_daynight(df, **kwargs):\n",
    "    print('Transforming to daynight...')\n",
    "    try:\n",
    "        category = kwargs.get('category',False)\n",
    "        index = ['count_date','year','day_name','week_name']\n",
    "        if category:\n",
    "            index = index + [category]\n",
    "        transform = df.pivot_table(\n",
    "            index =index,\n",
    "            columns='day_night',\n",
    "            values='corrected_value_total'\n",
    "        ).reset_index()\n",
    "        return transform\n",
    "    except Exception as e:\n",
    "        print(f'Error transforming to daynight: {e}')\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typical_footfall(footfall_data, start, end, **kwargs):\n",
    "    print('Calculating typical daily footfall...\\nFor Weedays and Weekends and Weekly averages...')\n",
    "    columns = [\n",
    "        'OID_','Col_ID','Row_ID','Hex_ID',\n",
    "        'Centroid_X','Centroid_Y','area',\n",
    "        'Shape_Length','Shape_Area'\n",
    "    ]\n",
    "    for column in columns:\n",
    "        if column in footfall_data.columns:\n",
    "            footfall_data = footfall_data.drop(columns=column)\n",
    "\n",
    "    footfall_data['count_date'] = pd.to_datetime(footfall_data['count_date'])\n",
    "\n",
    "    footfall_data = footfall_data[\n",
    "        (footfall_data['count_date'] <= pd.to_datetime(end)) &\n",
    "        (footfall_data['count_date'] >= pd.to_datetime(start))]\n",
    "    \n",
    "\n",
    "    columns_to_fill = [\n",
    "        'resident','worker','visitor',\n",
    "        'loyalty_percentage','dwell_time'\n",
    "    ]\n",
    "    footfall_data.loc[:, columns_to_fill] = footfall_data[columns_to_fill].applymap(lambda x: np.nan if x < 0 else x)\n",
    "    footfall_data[columns_to_fill] = footfall_data[columns_to_fill].fillna(0)\n",
    "    footfall_data = footfall_data.sort_values(by=['count_date','time_indicator','hex_id'])\n",
    "    \n",
    "\n",
    "    footfall_data = agg_footfall_data(\n",
    "        footfall_data,\n",
    "        category=kwargs.get('category','hex_id'),\n",
    "        agg=kwargs.get('agg','sum'),\n",
    "        footfall_type=kwargs.get('footfall_type',['residents','workers','visitors'])\n",
    "    )\n",
    "    \n",
    "    if kwargs.get('day_night',False):\n",
    "        footfall_data = transform_to_daynight(footfall_data, category='hex_id')\n",
    "        averages = footfall_data.copy()\n",
    "        averages = averages.groupby(['year','week_name','hex_id']).agg(\n",
    "            daytime_mean = ('6am-6pm','mean'),\n",
    "            nighttime_mean = ('6pm-6am','mean')\n",
    "        ).reset_index()\n",
    "        weekday = averages[averages['week_name'] == 'Weekday']\n",
    "        weekend = averages[averages['week_name'] == 'Weekend']\n",
    "        typical = footfall_data.groupby(['year','hex_id']).agg(\n",
    "            daytime_mean = ('6am-6pm','mean'),\n",
    "            nighttime_mean = ('6pm-6am','mean')\n",
    "        ).reset_index()\n",
    "    else:\n",
    "        averages = footfall_data.copy()\n",
    "        averages = averages.groupby(['year','week_name','hex_id']).agg(\n",
    "            averages = ('corrected_value_total','mean'),\n",
    "        ).reset_index()\n",
    "        weekday = averages[averages['week_name'] == 'Weekday']\n",
    "        weekend = averages[averages['week_name'] == 'Weekend']\n",
    "        typical = footfall_data.groupby(['year','hex_id']).agg(\n",
    "            averages = ('corrected_value_total','mean'),\n",
    "        ).reset_index()\n",
    "\n",
    "    typical_footfall = {\n",
    "        0 : typical,\n",
    "        1 : weekday,\n",
    "        2 : weekend\n",
    "    }\n",
    "\n",
    "    return typical_footfall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database and CWD setup and connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in 'C:\\\\Users\\\\jf79\\\\OneDrive - Office Shared Service\\\\Documents\\\\H&F Analysis\\\\Footfall and Spend Analysis\\\\Footfall Data\\\\LSOA Based': ['lsoa_hourly_counts_2022_H1.csv', 'lsoa_hourly_counts_2022_H2.csv', 'lsoa_hourly_counts_2024_H2.csv']\n"
     ]
    }
   ],
   "source": [
    "# Database credentials\n",
    "db_host = 'LBHHLWSQL0001.lbhf.gov.uk'\n",
    "db_port = '1433'\n",
    "db_name = 'IA_ODS'\n",
    "\n",
    "# Create the connection string for SQL Server using pyodbc with Windows Authentication\n",
    "connection_string = f'mssql+pyodbc://@{db_host}:{db_port}/{db_name}?driver=ODBC+Driver+17+for+SQL+Server&Trusted_Connection=yes'\n",
    "\n",
    "# Create the database engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Define the current working directory\n",
    "cwd = r'C:\\Users\\jf79\\OneDrive - Office Shared Service\\Documents\\H&F Analysis\\Footfall and Spend Analysis\\Footfall Data\\LSOA Based'\n",
    "os.chdir(cwd)\n",
    "files = os.listdir(os.getcwd())\n",
    "print(\"Files in %r: %s\" % (cwd, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "footfall_2024_Hex = pd.read_csv('C:/Users/jf79/OneDrive - Office Shared Service/Documents/H&F Analysis/Footfall and Spend Analysis/Footfall Data/Hex Based/Footfall Counts/hex_3hourly_counts_2024.csv')\n",
    "relevant_hexes = pd.read_csv('C:/Users/jf79/OneDrive - Office Shared Service/Documents/H&F Analysis/Footfall and Spend Analysis/Footfall Data/Hex Based/Relevant Hexes/Relevant Hexes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "footfall_data_2024 = footfall_2024_Hex.copy()\n",
    "relevant_hexes_data = relevant_hexes.copy()\n",
    "\n",
    "footfall_data_2024 = pd.merge(\n",
    "    relevant_hexes_data,\n",
    "    footfall_2024_Hex,\n",
    "    left_on='Hex_ID',\n",
    "    right_on='hex_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating typical daily footfall...\n",
      "For Weedays and Weekends and Weekly averages...\n",
      "Aggregating footfall data...\n",
      "Missing kwargs: {'day_night'}\n",
      "These args will be set to default values\n",
      "Applying features...\n",
      "Detecting anomalies...\n",
      "Detecting anomalies...\n",
      "Detecting anomalies...\n",
      "Transforming to daynight...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>hex_id</th>\n",
       "      <th>daytime_mean</th>\n",
       "      <th>nighttime_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2024</td>\n",
       "      <td>11281238</td>\n",
       "      <td>34128.001171</td>\n",
       "      <td>15796.983607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2024</td>\n",
       "      <td>11271229</td>\n",
       "      <td>10545.346995</td>\n",
       "      <td>5125.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2024</td>\n",
       "      <td>11271227</td>\n",
       "      <td>10249.332943</td>\n",
       "      <td>7134.401249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2024</td>\n",
       "      <td>11341220</td>\n",
       "      <td>5803.598361</td>\n",
       "      <td>3177.352459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2024</td>\n",
       "      <td>11261228</td>\n",
       "      <td>5639.672131</td>\n",
       "      <td>2039.199454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2024</td>\n",
       "      <td>11241248</td>\n",
       "      <td>19.455894</td>\n",
       "      <td>8.875878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2024</td>\n",
       "      <td>11271217</td>\n",
       "      <td>9.000390</td>\n",
       "      <td>1.226776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2024</td>\n",
       "      <td>11271219</td>\n",
       "      <td>8.975020</td>\n",
       "      <td>3.305621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2024</td>\n",
       "      <td>11251247</td>\n",
       "      <td>5.265027</td>\n",
       "      <td>0.535909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2024</td>\n",
       "      <td>11241246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year    hex_id  daytime_mean  nighttime_mean\n",
       "114  2024  11281238  34128.001171    15796.983607\n",
       "92   2024  11271229  10545.346995     5125.666667\n",
       "91   2024  11271227  10249.332943     7134.401249\n",
       "180  2024  11341220   5803.598361     3177.352459\n",
       "73   2024  11261228   5639.672131     2039.199454\n",
       "..    ...       ...           ...             ...\n",
       "53   2024  11241248     19.455894        8.875878\n",
       "86   2024  11271217      9.000390        1.226776\n",
       "87   2024  11271219      8.975020        3.305621\n",
       "67   2024  11251247      5.265027        0.535909\n",
       "52   2024  11241246      0.000000        0.000000\n",
       "\n",
       "[205 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week_name</th>\n",
       "      <th>hex_id</th>\n",
       "      <th>daytime_mean</th>\n",
       "      <th>nighttime_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11281238</td>\n",
       "      <td>29883.679389</td>\n",
       "      <td>15217.362595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11271229</td>\n",
       "      <td>10925.576336</td>\n",
       "      <td>5139.297710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11271227</td>\n",
       "      <td>10133.927481</td>\n",
       "      <td>7074.477099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11281224</td>\n",
       "      <td>6506.441658</td>\n",
       "      <td>1749.984733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11251239</td>\n",
       "      <td>6353.250273</td>\n",
       "      <td>1563.369138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11241248</td>\n",
       "      <td>22.681570</td>\n",
       "      <td>10.139586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11271219</td>\n",
       "      <td>8.763904</td>\n",
       "      <td>4.140676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11271217</td>\n",
       "      <td>8.085605</td>\n",
       "      <td>1.465649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11251247</td>\n",
       "      <td>7.037077</td>\n",
       "      <td>0.702835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>11241246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year week_name    hex_id  daytime_mean  nighttime_mean\n",
       "114  2024   Weekday  11281238  29883.679389    15217.362595\n",
       "92   2024   Weekday  11271229  10925.576336     5139.297710\n",
       "91   2024   Weekday  11271227  10133.927481     7074.477099\n",
       "107  2024   Weekday  11281224   6506.441658     1749.984733\n",
       "63   2024   Weekday  11251239   6353.250273     1563.369138\n",
       "..    ...       ...       ...           ...             ...\n",
       "53   2024   Weekday  11241248     22.681570       10.139586\n",
       "87   2024   Weekday  11271219      8.763904        4.140676\n",
       "86   2024   Weekday  11271217      8.085605        1.465649\n",
       "67   2024   Weekday  11251247      7.037077        0.702835\n",
       "52   2024   Weekday  11241246      0.000000        0.000000\n",
       "\n",
       "[205 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week_name</th>\n",
       "      <th>hex_id</th>\n",
       "      <th>daytime_mean</th>\n",
       "      <th>nighttime_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11281238</td>\n",
       "      <td>44820.427198</td>\n",
       "      <td>17257.182692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11271227</td>\n",
       "      <td>10540.065934</td>\n",
       "      <td>7285.364011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11271229</td>\n",
       "      <td>9587.461538</td>\n",
       "      <td>5091.326923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11281236</td>\n",
       "      <td>5818.270604</td>\n",
       "      <td>3531.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11341220</td>\n",
       "      <td>5739.125000</td>\n",
       "      <td>3284.516484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11241248</td>\n",
       "      <td>11.329670</td>\n",
       "      <td>5.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11271217</td>\n",
       "      <td>11.304945</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11271219</td>\n",
       "      <td>9.506868</td>\n",
       "      <td>1.201923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11251247</td>\n",
       "      <td>0.800824</td>\n",
       "      <td>0.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2024</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>11241246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year week_name    hex_id  daytime_mean  nighttime_mean\n",
       "319  2024   Weekend  11281238  44820.427198    17257.182692\n",
       "296  2024   Weekend  11271227  10540.065934     7285.364011\n",
       "297  2024   Weekend  11271229   9587.461538     5091.326923\n",
       "318  2024   Weekend  11281236   5818.270604     3531.192308\n",
       "385  2024   Weekend  11341220   5739.125000     3284.516484\n",
       "..    ...       ...       ...           ...             ...\n",
       "258  2024   Weekend  11241248     11.329670        5.692308\n",
       "291  2024   Weekend  11271217     11.304945        0.625000\n",
       "292  2024   Weekend  11271219      9.506868        1.201923\n",
       "272  2024   Weekend  11251247      0.800824        0.115385\n",
       "257  2024   Weekend  11241246      0.000000        0.000000\n",
       "\n",
       "[205 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform the data to Annual/Quarterly averages\n",
    "# def annual_quarterly_averages(df, start, end):\n",
    "#     typical_day_averages = typical_footfall(\n",
    "#         df, f'{start}', f'{end}'\n",
    "#     )\n",
    "#     for i in range(len(typical_day_averages)):\n",
    "#         display(typical_day_averages[i].sort_values(by='averages', ascending=False))\n",
    "\n",
    "typical_day_averages = typical_footfall(\n",
    "    footfall_data_2024, '2024-01-01', '2024-12-31',\n",
    "    footfall_type=['residents','workers','visitors'],\n",
    "    day_night=True\n",
    ")\n",
    "for i in range(len(typical_day_averages)):\n",
    "    if 'averages' in typical_day_averages[i].columns.to_list():\n",
    "        display(typical_day_averages[i].sort_values(by='averages', ascending=False))\n",
    "    elif 'daytime_mean' in typical_day_averages[i].columns.to_list():\n",
    "        display(typical_day_averages[i].sort_values(by='daytime_mean', ascending=False))\n",
    "    else:\n",
    "        display(typical_day_averages[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Successfully exported weekend_hf (annual) (day_night) to CSV\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "export_to_csv(typical_day_averages[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
